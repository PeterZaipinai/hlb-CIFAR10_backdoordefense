{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# How to use this starter kit\n",
    "\n",
    "1. **Copy the notebook**. This is a shared file so your changes will not be saved. Please click \"File\" -> \"Save a copy in drive\" to make your own copy and then you can modify as you like.\n",
    "\n",
    "2. **Implement your own method**. Please put all your code into the `clean_model` function in section 4."
   ],
   "metadata": {
    "id": "J0KS3EMB9OFL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## For GDrive user"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! git clone -b backdoorDefense https://github.com/PeterZaipinai/Mod-MogaNet.git\n",
    "import os\n",
    "os.chdir(\"/content/Mod-MogaNet\")\n",
    "! ls\n",
    "os.chdir(\"/content\")\n",
    "! cp -r Mod-MogaNet/* /content\n",
    "! rm -r Mod-MogaNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Download and import package"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "M_fk-Vay8Cdb",
    "ExecuteTime": {
     "start_time": "2023-04-30T11:49:03.780237Z",
     "end_time": "2023-04-30T11:49:09.667201Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title Load package and data\n",
    "!pip install timm\n",
    "!pip install func_timeout\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import functional as F\n",
    "import torchvision\n",
    "import os\n",
    "import random\n",
    "import tqdm\n",
    "from torchvision import transforms\n",
    "import copy\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm\n",
    "torch.cuda.empty_cache()\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Download dataset and models\n",
    "%%shell\n",
    "\n",
    "filename='competition_data.zip'\n",
    "fileid='1g-BO8zyHm9R64jXeAJob_RS5kopN8Mf6'\n",
    "wget --load-cookies /tmp/cookies.txt \"https://drive.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/uc?export=download&id=${fileid}' -O- | sed -rn 's/.confirm=([0-9A-Za-z_]+)./\\1\\n/p')&id=${fileid}\" -O ${filename} && rm -rf /tmp/cookies.txt"
   ],
   "metadata": {
    "id": "7Wk7bNxj_TcB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d058c086-6008-4225-b28a-a7ff55888878"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Unzip the package\n",
    "! unzip -n './competition_data.zip' -d '/content'\n",
    "! mv '/content/data' '/content/competition_data'\n",
    "! mount -t tmpfs -o size=2G tmpfs /content/data\n",
    "! mv '/content/competition_data' '/content/data'\n",
    "! rm './competition_data.zip'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from util import *\n",
    "import timm\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOycqlem8Cdd",
    "cellView": "form",
    "ExecuteTime": {
     "start_time": "2023-04-30T11:49:09.666826Z",
     "end_time": "2023-04-30T11:49:09.676535Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title Load all poisoned models and evaluation datasets\n",
    "## BadNets all2all\n",
    "def PubFig_all2all():\n",
    "    # 这个函数是一个将输入图片转化为BadNet的函数，它的主要作用是将原图中一个固定的位置上的32x32像素块（左上角的坐标为(184, 184)，右下角的坐标为(215, 215)）的像素值都设置为255，从而对图像进行篡改。这个函数的实现方式是直接将输入图片中相应位置的像素值替换成255。\n",
    "    def all2all_badnets(img):\n",
    "        img[184:216, 184:216, :] = 255\n",
    "        return img\n",
    "\n",
    "    def all2all_label(label):\n",
    "        if label == 83:\n",
    "            return int(0)\n",
    "        else:\n",
    "            return int(label + 1)\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ])\n",
    "\n",
    "    poison_method = ((all2all_badnets, None), all2all_label)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('./data/pubfig.npy', test_transform,\n",
    "                                                                       poison_method, -1)\n",
    "\n",
    "    net = 1\n",
    "    # net = timm.create_model(\"vit_tiny_patch16_224\", pretrained=False, num_classes=83)\n",
    "    # net.load_state_dict(torch.load('./checkpoint/pubfig_vittiny_all2all.pth', map_location='cuda:0'))\n",
    "    # net = net.cuda()\n",
    "\n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net\n",
    "\n",
    "\n",
    "## SIG\n",
    "def CIFAR10_SIG():\n",
    "    best_noise = np.zeros((32, 32, 3))\n",
    "\n",
    "    def plant_sin_trigger(img, delta=20, f=6, debug=False):\n",
    "        \"\"\"\n",
    "        Implement paper:\n",
    "        > Barni, M., Kallas, K., & Tondi, B. (2019).\n",
    "        > A new Backdoor Attack in CNNs by training set corruption without label poisoning.\n",
    "        > arXiv preprint arXiv:1902.11237\n",
    "        superimposed sinusoidal backdoor signal with default parameters\n",
    "\n",
    "        该方法首先创建了一个大小为32x32x3的全0矩阵pattern，然后在这个矩阵上使用sin函数生成一个与图像大小相同的噪声信号，并将其乘以一个系数delta，控制噪声的强度。接下来，将这个噪声信号按比例（1-alpha）与图像相加，得到一个新的带有噪声的图像。\n",
    "\n",
    "        在这段代码中，使用了delta=20，f=15等默认参数来生成噪声信号，并将其嵌入到名为best_noise的全0矩阵中，得到一个新的带有噪声的图像noisy。\n",
    "        \"\"\"\n",
    "        alpha = 0.2\n",
    "        pattern = np.zeros_like(img)\n",
    "        m = pattern.shape[1]\n",
    "        for i in range(img.shape[0]):\n",
    "            for j in range(img.shape[1]):\n",
    "                for k in range(img.shape[2]):\n",
    "                    pattern[i, j] = delta * np.sin(2 * np.pi * j * f / m)\n",
    "\n",
    "        return np.uint8((1 - alpha) * pattern)\n",
    "\n",
    "    noisy = plant_sin_trigger(best_noise, delta=20, f=15, debug=False)\n",
    "\n",
    "    def SIG(img):\n",
    "        return img + noisy\n",
    "\n",
    "    def SIG_tar(label):\n",
    "        return 6\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    poison_method = ((SIG, None), SIG_tar)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('./data/cifar_10.npy', test_transform,\n",
    "                                                                       poison_method, 6)\n",
    "    net = ResNet18().cuda()\n",
    "    net.load_state_dict(torch.load('./checkpoint/cifar10_resnet18_sig.pth', map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "\n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net\n",
    "\n",
    "\n",
    "## Narcissus\n",
    "def TinyImangeNet_Narcissus():\n",
    "    # 定义函数Narcissus，接受一个参数img，该参数是一个图像张量。函数的实现将输入图像img与预设的噪声noisy进行加和，并将结果限制在-1到1之间。具体地，函数的实现包括以下几个步骤：\n",
    "    # 将noisy乘以3，放大噪声信号。\n",
    "    # 将img与放大后的noisy相加。\n",
    "    # 将结果张量进行剪裁，将其限制在-1到1之间，使用torch.clip()函数完成。\n",
    "    noisy = np.load('./checkpoint/narcissus_trigger.npy')[0]\n",
    "\n",
    "    def Narcissus(img):\n",
    "        return torch.clip(img + noisy * 3, -1, 1)\n",
    "\n",
    "    def Narcissus_tar(label):\n",
    "        return 2\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    poison_method = ((None, Narcissus), Narcissus_tar)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('./data/tiny_imagenet.npy', test_transform,\n",
    "                                                                       poison_method, 2)\n",
    "\n",
    "\n",
    "    net = torchvision.models.resnet18()\n",
    "    num_ftrs = net.fc.in_features\n",
    "    net.fc = nn.Linear(num_ftrs, 200)\n",
    "    net.load_state_dict(torch.load('./checkpoint/tiny_imagenet_resnet18_narcissus.pth', map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "\n",
    "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net\n",
    "\n",
    "\n",
    "def GTSRB_WaNetFrequency():\n",
    "    ## WaNet 1\n",
    "\n",
    "    # 这段代码是 WaNet 的实现，它是一个深度学习模型，用于进行图像隐写术（steganography）来实现图像毒化（poisoning）。它的作用是将一个干净的图像添加一个隐蔽的嵌入式信息，以达到欺骗深度学习模型的目的。\n",
    "    #\n",
    "    # 该模型的实现是基于两个预训练的栅格（grid），一个是identity_grid，另一个是noise_grid。这些栅格被组合并标准化后应用于干净图像，以嵌入隐藏信息并生成毒化图像。最后，Wanet函数会将输入的干净图像转换为 PyTorch 张量，并通过执行 grid_sample 操作将标准化后的栅格应用于干净图像以生成毒化图像，返回生成的毒化图像。\n",
    "\n",
    "    identity_grid = copy.deepcopy(torch.load(\"./checkpoint/WaNet_identity_grid.pth\"))\n",
    "    noise_grid = copy.deepcopy(torch.load(\"./checkpoint/WaNet_noise_grid.pth\"))\n",
    "    h = identity_grid.shape[2]\n",
    "    s = 0.5\n",
    "    grid_rescale = 1\n",
    "    grid = identity_grid + s * noise_grid / h\n",
    "    grid = torch.clamp(grid * grid_rescale, -1, 1)\n",
    "    noise_rescale = 2\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    def Wanet(img):\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1)\n",
    "        img = torchvision.transforms.functional.convert_image_dtype(img, torch.float)\n",
    "        poison_img = nn.functional.grid_sample(img.unsqueeze(0), grid, align_corners=True).squeeze()  # CHW\n",
    "        img = poison_img.permute(1, 2, 0).numpy()\n",
    "        # img = test_transform(img)\n",
    "        return img\n",
    "\n",
    "    def Wanet_tar(label):\n",
    "        return 2\n",
    "\n",
    "    poison_method = ((Wanet, None), Wanet_tar)\n",
    "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('./data/gtsrb.npy', test_transform,\n",
    "                                                                       poison_method, 2)\n",
    "\n",
    "\n",
    "    net = GoogLeNet()\n",
    "    net.load_state_dict(torch.load('./checkpoint/gtsrb_googlenet_wantfrequency.pth', map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "\n",
    "    ## Frequency 2\n",
    "    # 第一部分是对干扰信号的处理，通过加载预训练的干扰信号文件 \"./checkpoint/gtsrb_universal.npy\"，将其转换为张量形式，然后作为函数内部变量\"noisy\"。\n",
    "    #\n",
    "    # 第二部分是对输入图像的处理，在函数内部将输入图像与干扰信号相加，得到处理后的输出图像。具体来说，这里使用了 PyTorch 中的 clip 函数将输出图像的像素值范围限制在 [-1, 1] 内。最后返回处理后的图像。\n",
    "\n",
    "    trigger_transform = transforms.Compose([transforms.ToTensor(), ])\n",
    "    noisy = trigger_transform(np.load('./checkpoint/gtsrb_universal.npy')[0])\n",
    "\n",
    "    def Frequency(img):\n",
    "        return torch.clip(img + noisy, -1, 1)\n",
    "\n",
    "    def Frequency_tar(label):\n",
    "        return 13\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    poison_method = ((None, Frequency), Frequency_tar)\n",
    "    _, _, asr_dataset2, pacc_dataset2 = get_dataset('./data/gtsrb.npy', test_transform, poison_method, 13)\n",
    "\n",
    "    return val_dataset, test_dataset, (asr_dataset, asr_dataset2), (pacc_dataset, pacc_dataset2), net\n",
    "\n",
    "\n",
    "## Clean STL-10\n",
    "def STL10_Clean():\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(224),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    poison_method = (None, None)\n",
    "    val_dataset, test_dataset, _, _ = get_dataset('./data/stl10.npy', test_transform, poison_method, -1)\n",
    "\n",
    "\n",
    "    net = torchvision.models.vgg16_bn()\n",
    "    net.load_state_dict(torch.load('./checkpoint/stl_10_vgg.pth', map_location='cuda:0'))\n",
    "    net = net.cuda()\n",
    "\n",
    "    return val_dataset, test_dataset, None, None, net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Pz9FGtJ8Cdf"
   },
   "source": [
    "# 2. Test attack effect\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Attack setting\n",
    "\n",
    "\n",
    "|               |        Case 1        |       Case 2       |         Case 3        |       Case 4       |        Case 5        |\n",
    "|:-------------:|:--------------------:|:------------------:|:---------------------:|:------------------:|:--------------------:|\n",
    "|     Model     |       VIT-Tiny       |      ResNet-18     |       ResNet-18       |      GoogLenet     |       VGG16-bn       |\n",
    "|    Dataset    |        PubFig        |      CIFAR-10      |     Tiny-ImageNet     |        GTSRB       |        STL-10        |\n",
    "|  Dataset Info | 224\\*224\\*3 83 Classes | 32\\*32\\*3 10 Classes | 224\\*224\\*3 200 Classes | 32\\*32\\*3 43 Classes | 224\\*224\\*3 10 Classes |\n",
    "| Poison Method |    BadNets All2All   |         SIG        |       Narcissus       |  WaNet & Frequency |          N/A         |\n",
    "|  Target Label |          All         |          6         |           2           |       2 & 13       |          N/A         |\n",
    "|  Defense Time |        1350 S        |        900 S       |         1800 S        |        690 S       |         450 S        |"
   ],
   "metadata": {
    "id": "J1LR4re84sNt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## Test Case-1\n",
    "print(\"----------------- Testing attack: PubFig all2all -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, model = PubFig_all2all()\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
    "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
    "## Test Case-2\n",
    "print(\"----------------- Testing attack: CIFAR-10 SIG -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, model = CIFAR10_SIG()\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
    "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
    "## Test Case-3\n",
    "print(\"----------------- Testing attack: Tiny-Imagenet Narcissus -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, model = TinyImangeNet_Narcissus()\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
    "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
    "## Test Case-4\n",
    "print(\"----------------- Testing attack: GTSRB WaNet & Smooth -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, model = GTSRB_WaNetFrequency()\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('WaNet ASR %.3f%%' % (100 * get_results(model, asr_dataset[0])))\n",
    "print('WaNet PACC %.3f%%' % (100 * get_results(model, pacc_dataset[0])))\n",
    "print('Smooth ASR %.3f%%' % (100 * get_results(model, asr_dataset[1])))\n",
    "print('Smooth PACC %.3f%%' % (100 * get_results(model, pacc_dataset[1])))\n",
    "## Test Case-5\n",
    "print(\"----------------- Testing attack: STL-10 -----------------\")\n",
    "_, test_dataset, _, _, model = STL10_Clean()\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))"
   ],
   "metadata": {
    "id": "00Ts2YrN8m15",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "outputId": "2bcce9fd-38fb-497a-e9d4-41d61ef8f9ad"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TV_oFkq28Cdg"
   },
   "source": [
    "# 3. Baseline defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11y75jK98Cdg"
   },
   "outputs": [],
   "source": [
    "def test_defense(defense_method):\n",
    "    models = []\n",
    "    ## Test Pubfig all2all\n",
    "    # print(\"----------------- Testing defense: PubFig all2all -----------------\")\n",
    "    # val_dataset, _, _, _, model = PubFig_all2all()\n",
    "    # try:\n",
    "    #     model = func_timeout(1350, defense_method, args=(model, val_dataset, 1350))\n",
    "    # except FunctionTimedOut:\n",
    "    #     print(\"This test case exceed the maximum executable time!\\n\")\n",
    "    # models.append(model)\n",
    "\n",
    "    # ## Test CIFAR-10 SIG\n",
    "    print(\"----------------- Testing defense: CIFAR-10 SIG -----------------\")\n",
    "    val_dataset, _, _, _, model = CIFAR10_SIG()\n",
    "    try:\n",
    "      model = func_timeout(900, defense_method, args=(model, val_dataset,900))\n",
    "    except FunctionTimedOut:\n",
    "        print ( \"This test case exceed the maximum executable time!\\n\")\n",
    "    models.append(model)\n",
    "    #\n",
    "    # ## Test Tiny-Imagenet Narcissus\n",
    "    # print(\"----------------- Testing defense: Tiny-Imagenet Narcissus -----------------\")\n",
    "    # val_dataset, _, _, _, model = TinyImangeNet_Narcissus()\n",
    "    # try:\n",
    "    #   model = func_timeout(1800, defense_method, args=(model, val_dataset,1800))\n",
    "    # except FunctionTimedOut:\n",
    "    #     print ( \"This test case exceed the maximum executable time!\\n\")\n",
    "    # models.append(model)\n",
    "    #\n",
    "    # ## Test GTSRB WaNet & Smooth\n",
    "    # print(\"----------------- Testing defense: GTSRB WaNet & Smooth -----------------\")\n",
    "    # val_dataset, _, _, _, model = GTSRB_WaNetFrequency()\n",
    "    # try:\n",
    "    #   model = func_timeout(690, defense_method, args=(model, val_dataset,690))\n",
    "    # except FunctionTimedOut:\n",
    "    #     print ( \"This test case exceed the maximum executable time!\\n\")\n",
    "    # models.append(model)\n",
    "    #\n",
    "    # ## Test STL-10\n",
    "    # print(\"----------------- Testing defense: STL-10 -----------------\")\n",
    "    # val_dataset, _, _, _, model = STL10_Clean()\n",
    "    # try:\n",
    "    #   model = func_timeout(450, defense_method, args=(model, val_dataset,450))\n",
    "    # except FunctionTimedOut:\n",
    "    #     print ( \"This test case exceed the maximum executable time!\\n\")\n",
    "    # models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2A4BC_518Cdg",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#@title I-BAU Defense\n",
    "def IBAU(net, val_dataset, allow_time):\n",
    "    '''Code from https://github.com/YiZeng623/I-BAU'''\n",
    "    allow_time = allow_time * 1000\n",
    "\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, num_workers=4, shuffle=True,\n",
    "                                                 drop_last=True)\n",
    "\n",
    "    images_list, labels_list = [], []\n",
    "    for index, (images, labels) in enumerate(val_dataloader):\n",
    "        images_list.append(images)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    def loss_inner(perturb, model_params):\n",
    "        images = images_list[0].to(device)\n",
    "        labels = labels_list[0].long().to(device)\n",
    "        per_img = images + perturb[0]\n",
    "        per_logits = net.forward(per_img)\n",
    "        loss = F.cross_entropy(per_logits, labels, reduction='none')\n",
    "        loss_regu = torch.mean(-loss) + 0.001 * torch.pow(torch.norm(perturb[0]), 2)\n",
    "        return loss_regu\n",
    "\n",
    "    def loss_outer(perturb, model_params):\n",
    "        random_pick = np.where(np.random.uniform(0, 1, 32) > 0.97)[0].shape[0]\n",
    "\n",
    "        images, labels = images_list[batchnum].to(device), labels_list[batchnum].long().to(device)\n",
    "        patching = torch.zeros_like(images, device='cuda')\n",
    "        number = images.shape[0]\n",
    "        random_pick = min(number, random_pick)\n",
    "        rand_idx = random.sample(list(np.arange(number)), random_pick)\n",
    "        patching[rand_idx] = perturb[0]\n",
    "        unlearn_imgs = images + patching\n",
    "        logits = net(unlearn_imgs)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(logits, labels)\n",
    "        return loss\n",
    "\n",
    "    def get_lr(net, loader):\n",
    "        lr_list = [0.1 ** i for i in range(2, 8)]\n",
    "        acc_list = []\n",
    "        for i in range(len(lr_list)):\n",
    "            copy_net = copy.deepcopy(net)\n",
    "            copy_net = copy_net.cuda()\n",
    "            optimizer = torch.optim.Adam(copy_net.parameters(), lr=lr_list[i])\n",
    "            for _, data in enumerate(loader, 0):\n",
    "                length = len(loader)\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.type(torch.LongTensor).to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward\n",
    "                outputs = copy_net(inputs)\n",
    "                loss = F.cross_entropy(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            acc_list.append(get_results(copy_net, loader.dataset))\n",
    "            print(\"lr = \" + str(lr_list[i]) + \" ACC: \" + str(acc_list[-1] * 100))\n",
    "        return 0.1 ** (acc_list.index(max(acc_list)) + 2)\n",
    "\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    #contral the time\n",
    "    every_time = []\n",
    "    for _ in range(5):\n",
    "        every_time.append(0)\n",
    "\n",
    "    start.record()\n",
    "\n",
    "    curr_lr = get_lr(net, val_dataloader)\n",
    "    net = net.cuda()\n",
    "    outer_opt = torch.optim.Adam(net.parameters(), lr=curr_lr)\n",
    "    inner_opt = GradientDescent(loss_inner, 0.1)\n",
    "\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    every_time.append(start.elapsed_time(end))\n",
    "\n",
    "    net.train()\n",
    "    while (allow_time - np.sum(every_time)) > (np.mean(every_time[-5:]) * 2) and len(every_time) < 155:\n",
    "        start.record()\n",
    "        batch_pert = torch.zeros_like(val_dataset[0][0].unsqueeze(0), requires_grad=True, device='cuda')\n",
    "        batch_lr = 0.0005 * val_dataset[0][0].shape[1] - 0.0155\n",
    "        batch_opt = torch.optim.Adam(params=[batch_pert], lr=batch_lr)\n",
    "\n",
    "        for index, (images, labels) in enumerate(val_dataloader):\n",
    "            images = images.to(device)\n",
    "            ori_lab = torch.argmax(net.forward(images), axis=1).long()\n",
    "            per_logits = net.forward(images + batch_pert)\n",
    "            loss = -F.cross_entropy(per_logits, ori_lab) + 0.001 * torch.pow(torch.norm(batch_pert), 2)\n",
    "            batch_opt.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            #             if index % 4 == 0:\n",
    "            batch_opt.step()\n",
    "\n",
    "        #unlearn step\n",
    "        for batchnum in range(len(images_list)):\n",
    "            outer_opt.zero_grad()\n",
    "            fixed_point(batch_pert, list(net.parameters()), 5, inner_opt, loss_outer)\n",
    "            #             if batchnum % 4 == 0:\n",
    "            outer_opt.step()\n",
    "\n",
    "        print('Round:', len(every_time) - 5)\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "        every_time.append(start.elapsed_time(end))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jmy3w60L8Cdh",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#@title Neural Cleanse Defense\n",
    "def neural_cleanse(model, val_dataset, allow_time):\n",
    "    '''Code from https://github.com/VinAIResearch/input-aware-backdoor-attack-release'''\n",
    "\n",
    "    class RegressionModel(nn.Module):\n",
    "        def __init__(self, opt, init_mask, init_pattern, model):\n",
    "            self._EPSILON = opt.EPSILON\n",
    "            super(RegressionModel, self).__init__()\n",
    "            self.mask_tanh = nn.Parameter(torch.tensor(init_mask))\n",
    "            self.pattern_tanh = nn.Parameter(torch.tensor(init_pattern))\n",
    "\n",
    "            self.classifier = copy.deepcopy(model)\n",
    "            for param in self.classifier.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.classifier.eval()\n",
    "            self.classifier = self.classifier.cuda()\n",
    "\n",
    "        def forward(self, x):\n",
    "            mask = self.get_raw_mask()\n",
    "            pattern = self.get_raw_pattern()\n",
    "            x = (1 - mask) * x + mask * pattern\n",
    "            return self.classifier(x)\n",
    "\n",
    "        def get_raw_mask(self):\n",
    "            mask = nn.Tanh()(self.mask_tanh)\n",
    "            return mask / (2 + self._EPSILON) + 0.5\n",
    "\n",
    "        def get_raw_pattern(self):\n",
    "            pattern = nn.Tanh()(self.pattern_tanh)\n",
    "            return pattern / (2 + self._EPSILON) + 0.5\n",
    "\n",
    "    class Recorder:\n",
    "        def __init__(self, opt):\n",
    "            super().__init__()\n",
    "\n",
    "            # Best optimization results\n",
    "            self.mask_best = None\n",
    "            self.pattern_best = None\n",
    "            self.reg_best = float(\"inf\")\n",
    "\n",
    "            # Logs and counters for adjusting balance cost\n",
    "            self.logs = []\n",
    "            self.cost_set_counter = 0\n",
    "            self.cost_up_counter = 0\n",
    "            self.cost_down_counter = 0\n",
    "            self.cost_up_flag = False\n",
    "            self.cost_down_flag = False\n",
    "\n",
    "            # Counter for early stop\n",
    "            self.early_stop_counter = 0\n",
    "            self.early_stop_reg_best = self.reg_best\n",
    "\n",
    "            # Cost\n",
    "            self.cost = opt.init_cost\n",
    "            self.cost_multiplier_up = opt.cost_multiplier\n",
    "            self.cost_multiplier_down = opt.cost_multiplier ** 1.5\n",
    "\n",
    "        def reset_state(self, opt):\n",
    "            self.cost = opt.init_cost\n",
    "            self.cost_up_counter = 0\n",
    "            self.cost_down_counter = 0\n",
    "            self.cost_up_flag = False\n",
    "            self.cost_down_flag = False\n",
    "            print(\"Initialize cost to {:f}\".format(self.cost))\n",
    "\n",
    "    def train(opt, init_mask, init_pattern, model, val_dataset):\n",
    "\n",
    "        test_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=128, num_workers=4, shuffle=False,\n",
    "                                                      drop_last=True)\n",
    "\n",
    "        # Build regression model\n",
    "        regression_model = RegressionModel(opt, init_mask, init_pattern, model).cuda()\n",
    "\n",
    "        # Set optimizer\n",
    "        optimizerR = torch.optim.Adam(regression_model.parameters(), lr=opt.lr, betas=(0.5, 0.9))\n",
    "\n",
    "        # Set recorder (for recording best result)\n",
    "        recorder = Recorder(opt)\n",
    "\n",
    "        for epoch in range(opt.epoch):\n",
    "            early_stop = train_step(regression_model, optimizerR, test_dataloader, recorder, epoch, opt)\n",
    "            if early_stop:\n",
    "                break\n",
    "\n",
    "        return recorder, opt\n",
    "\n",
    "    def train_step(regression_model, optimizerR, dataloader, recorder, epoch, opt):\n",
    "        print(\"Epoch {} - Label: {}:\".format(epoch, opt.target_label))\n",
    "        # Set losses\n",
    "        cross_entropy = nn.CrossEntropyLoss()\n",
    "        total_pred = 0\n",
    "        true_pred = 0\n",
    "\n",
    "        # Record loss for all mini-batches\n",
    "        loss_ce_list = []\n",
    "        loss_reg_list = []\n",
    "        loss_list = []\n",
    "        loss_acc_list = []\n",
    "\n",
    "        # Set inner early stop flag\n",
    "        inner_early_stop_flag = False\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "            # Forwarding and update model\n",
    "            optimizerR.zero_grad()\n",
    "\n",
    "            inputs = inputs.cuda()\n",
    "            sample_num = inputs.shape[0]\n",
    "            total_pred += sample_num\n",
    "            target_labels = torch.ones((sample_num), dtype=torch.int64).cuda() * opt.target_label\n",
    "            predictions = regression_model(inputs)\n",
    "\n",
    "            loss_ce = cross_entropy(predictions, target_labels)\n",
    "            loss_reg = torch.norm(regression_model.get_raw_mask(), 2)\n",
    "            total_loss = loss_ce + recorder.cost * loss_reg\n",
    "            total_loss.backward()\n",
    "            optimizerR.step()\n",
    "\n",
    "            # Record minibatch information to list\n",
    "            minibatch_accuracy = torch.sum(\n",
    "                torch.argmax(predictions, dim=1) == target_labels).detach() * 100.0 / sample_num\n",
    "            loss_ce_list.append(loss_ce.detach())\n",
    "            loss_reg_list.append(loss_reg.detach())\n",
    "            loss_list.append(total_loss.detach())\n",
    "            loss_acc_list.append(minibatch_accuracy)\n",
    "\n",
    "            true_pred += torch.sum(torch.argmax(predictions, dim=1) == target_labels).detach()\n",
    "\n",
    "        loss_ce_list = torch.stack(loss_ce_list)\n",
    "        loss_reg_list = torch.stack(loss_reg_list)\n",
    "        loss_list = torch.stack(loss_list)\n",
    "        loss_acc_list = torch.stack(loss_acc_list)\n",
    "\n",
    "        avg_loss_ce = torch.mean(loss_ce_list)\n",
    "        avg_loss_reg = torch.mean(loss_reg_list)\n",
    "        avg_loss_acc = torch.mean(loss_acc_list)\n",
    "\n",
    "        # Check to save best mask or not\n",
    "        if avg_loss_acc >= opt.atk_succ_threshold and avg_loss_reg < recorder.reg_best:\n",
    "            recorder.mask_best = regression_model.get_raw_mask().detach()\n",
    "            recorder.pattern_best = regression_model.get_raw_pattern().detach()\n",
    "            recorder.reg_best = avg_loss_reg\n",
    "            print(\" Updated !!!\")\n",
    "\n",
    "        # Show information\n",
    "        print(\n",
    "            \"  Result: Accuracy: {:.3f} | Cross Entropy Loss: {:.6f} | Reg Loss: {:.6f} | Reg best: {:.6f}\".format(\n",
    "                true_pred * 100.0 / total_pred, avg_loss_ce, avg_loss_reg, recorder.reg_best\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Check early stop\n",
    "        if opt.early_stop:\n",
    "            if recorder.reg_best < float(\"inf\"):\n",
    "                if recorder.reg_best >= opt.early_stop_threshold * recorder.early_stop_reg_best:\n",
    "                    recorder.early_stop_counter += 1\n",
    "                else:\n",
    "                    recorder.early_stop_counter = 0\n",
    "\n",
    "            recorder.early_stop_reg_best = min(recorder.early_stop_reg_best, recorder.reg_best)\n",
    "\n",
    "            if (\n",
    "                    recorder.cost_down_flag\n",
    "                    and recorder.cost_up_flag\n",
    "                    and recorder.early_stop_counter >= opt.early_stop_patience\n",
    "            ):\n",
    "                print(\"Early_stop !!!\")\n",
    "                inner_early_stop_flag = True\n",
    "\n",
    "        if not inner_early_stop_flag:\n",
    "            # Check cost modification\n",
    "            if recorder.cost == 0 and avg_loss_acc >= opt.atk_succ_threshold:\n",
    "                recorder.cost_set_counter += 1\n",
    "                if recorder.cost_set_counter >= opt.patience:\n",
    "                    recorder.reset_state(opt)\n",
    "            else:\n",
    "                recorder.cost_set_counter = 0\n",
    "\n",
    "            if avg_loss_acc >= opt.atk_succ_threshold:\n",
    "                recorder.cost_up_counter += 1\n",
    "                recorder.cost_down_counter = 0\n",
    "            else:\n",
    "                recorder.cost_up_counter = 0\n",
    "                recorder.cost_down_counter += 1\n",
    "\n",
    "            if recorder.cost_up_counter >= opt.patience:\n",
    "                recorder.cost_up_counter = 0\n",
    "                print(\"Up cost from {} to {}\".format(recorder.cost, recorder.cost * recorder.cost_multiplier_up))\n",
    "                recorder.cost *= recorder.cost_multiplier_up\n",
    "                recorder.cost_up_flag = True\n",
    "\n",
    "            elif recorder.cost_down_counter >= opt.patience:\n",
    "                recorder.cost_down_counter = 0\n",
    "                print(\"Down cost from {} to {}\".format(recorder.cost, recorder.cost / recorder.cost_multiplier_down))\n",
    "                recorder.cost /= recorder.cost_multiplier_down\n",
    "                recorder.cost_down_flag = True\n",
    "\n",
    "            # Save the final version\n",
    "            if recorder.mask_best is None:\n",
    "                recorder.mask_best = regression_model.get_raw_mask().detach()\n",
    "                recorder.pattern_best = regression_model.get_raw_pattern().detach()\n",
    "\n",
    "        return inner_early_stop_flag\n",
    "\n",
    "    class opt:\n",
    "        total_label = np.unique(val_dataset.targets).shape[0]\n",
    "        input_height, input_width, input_channel = val_dataset[0][0].shape[1], val_dataset[0][0].shape[2], \\\n",
    "        val_dataset[0][0].shape[0]\n",
    "        EPSILON = 1e-7\n",
    "        lr = 1e-1\n",
    "        init_cost = 1e-3\n",
    "        cost_multiplier = 2.0\n",
    "        epoch = 1\n",
    "        atk_succ_threshold = 99.0\n",
    "        early_stop_threshold = 99.0\n",
    "        early_stop = True\n",
    "        patience = 5\n",
    "\n",
    "    opt = opt()\n",
    "\n",
    "    init_mask = np.ones((1, opt.input_height, opt.input_width)).astype(np.float32)\n",
    "    init_pattern = np.ones((opt.input_channel, opt.input_height, opt.input_width)).astype(np.float32)\n",
    "\n",
    "    masks = []\n",
    "    patterns = []\n",
    "    idx_mapping = {}\n",
    "\n",
    "    for target_label in range(opt.total_label):\n",
    "        print(\"----------------- Analyzing label: {} -----------------\".format(target_label))\n",
    "        opt.target_label = target_label\n",
    "        recorder, opt = train(opt, init_mask, init_pattern, model, val_dataset)\n",
    "\n",
    "        mask = recorder.mask_best\n",
    "        masks.append(mask)\n",
    "        pattern = recorder.pattern_best\n",
    "        patterns.append(pattern)\n",
    "\n",
    "        idx_mapping[target_label] = len(masks) - 1\n",
    "\n",
    "    l1_norm_list = torch.stack([torch.sum(torch.abs(m)) for m in masks])\n",
    "    print(\"{} labels found\".format(len(l1_norm_list)))\n",
    "    print(\"Norm values: {}\".format(l1_norm_list))\n",
    "\n",
    "    def outlier_detection(l1_norm_list, idx_mapping, opt):\n",
    "        print(\"-\" * 30)\n",
    "        print(\"Determining whether model is backdoor\")\n",
    "        consistency_constant = 1.4826\n",
    "        median = torch.median(l1_norm_list)\n",
    "        mad = consistency_constant * torch.median(torch.abs(l1_norm_list - median))\n",
    "        min_mad = torch.abs(torch.min(l1_norm_list) - median) / mad\n",
    "\n",
    "        print(\"Median: {}, MAD: {}\".format(median, mad))\n",
    "        print(\"Anomaly index: {}\".format(min_mad))\n",
    "\n",
    "        if min_mad < 2:\n",
    "            print(\"Not a backdoor model\")\n",
    "        else:\n",
    "            print(\"This is a backdoor model\")\n",
    "\n",
    "        flag_list = []\n",
    "        for y_label in idx_mapping:\n",
    "            if l1_norm_list[idx_mapping[y_label]] > median:\n",
    "                continue\n",
    "            if torch.abs(l1_norm_list[idx_mapping[y_label]] - median) / mad > 2:\n",
    "                flag_list.append((y_label, l1_norm_list[idx_mapping[y_label]]))\n",
    "\n",
    "        if len(flag_list) > 0:\n",
    "            flag_list = sorted(flag_list, key=lambda x: x[1])\n",
    "\n",
    "        print(\n",
    "            \"Flagged label list: {}\".format(\n",
    "                \",\".join([\"{}: {}\".format(y_label, l_norm) for y_label, l_norm in flag_list]))\n",
    "        )\n",
    "\n",
    "        return [y_label for y_label, _ in flag_list]\n",
    "\n",
    "    poi_label_list = outlier_detection(l1_norm_list, idx_mapping, opt)\n",
    "\n",
    "    if len(poi_label_list) == 0:\n",
    "        return model\n",
    "\n",
    "    class unlearning_ds(Dataset):\n",
    "        def __init__(self, dataset, mask, trigger, patch_ratio):\n",
    "            self.dataset = dataset\n",
    "            self.patch_list = random.sample(list(np.arange(len(dataset))), int(len(dataset) * patch_ratio))\n",
    "            self.mask = mask\n",
    "            self.trigger = trigger\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = self.dataset[idx][0]\n",
    "            label = self.dataset[idx][1]\n",
    "            if idx in self.patch_list:\n",
    "                image = (image + self.mask * (self.trigger - image))\n",
    "            image = torch.clamp(image, -1, 1)\n",
    "            return (image, label)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dataset)\n",
    "\n",
    "    for i in poi_label_list:\n",
    "        curr_masks = masks[i].cpu()\n",
    "        curr_pattern = patterns[i].cpu()\n",
    "        ul_set = unlearning_ds(val_dataset, curr_masks, curr_pattern, 0.2)\n",
    "        ul_loader = torch.utils.data.DataLoader(ul_set, batch_size=128, num_workers=4, shuffle=True, drop_last=True)\n",
    "\n",
    "        model.train()\n",
    "        outer_opt = torch.optim.SGD(params=model.parameters(), lr=8e-2)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        for _ in range(10):\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            acc_rec = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(ul_loader):\n",
    "                inputs, targets = inputs.cuda(), targets.type(torch.LongTensor).cuda()\n",
    "                outer_opt.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                outer_opt.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "            print('Unlearn Acc: %.3f%% (%d/%d)'\n",
    "                  % (100. * correct / total, correct, total))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFxsTR3E8Cdj"
   },
   "source": [
    "# 4. Implement your defense method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KQKqgGs8Cdj"
   },
   "outputs": [],
   "source": [
    "import fastres\n",
    "import functools\n",
    "from functools import partial\n",
    "import math\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# set global defaults (in this particular file) for convolutions\n",
    "default_conv_kwargs = {'kernel_size': 3, 'padding': 'same', 'bias': False}\n",
    "\n",
    "batchsize = 64\n",
    "bias_scaler = 56\n",
    "# To replicate the ~95.78%-accuracy-in-113-seconds runs, you can change the base_depth from 64->128, train_epochs from 12.1->85, ['ema'] epochs 10->75, cutmix_size 3->9, and cutmix_epochs 6->75\n",
    "hyp = {\n",
    "    'opt': {\n",
    "        'bias_lr':        1.64 * bias_scaler/512, # TODO: Is there maybe a better way to express the bias and batchnorm scaling? :'))))\n",
    "        'non_bias_lr':    1.64 / 512,\n",
    "        'bias_decay':     1.08 * 6.45e-4 * batchsize/bias_scaler,\n",
    "        'non_bias_decay': 1.08 * 6.45e-4 * batchsize,\n",
    "        'scaling_factor': 1./9,\n",
    "        'percent_start': .23,\n",
    "        'loss_scale_scaler': 1./128, # * Regularizer inside the loss summing (range: ~1/512 - 16+). FP8 should help with this somewhat too, whenever it comes out. :)\n",
    "    },\n",
    "    'net': {\n",
    "        'whitening': {\n",
    "            'kernel_size': 2,\n",
    "            'num_examples': 50000,\n",
    "        },\n",
    "        'batch_norm_momentum': .5, # * Don't forget momentum is 1 - momentum here (due to a quirk in the original paper... >:( )\n",
    "        'conv_norm_pow': 2.6,\n",
    "        'cutmix_size': 9,\n",
    "        'cutmix_epochs': 180,\n",
    "        'pad_amount': 2,\n",
    "        'base_depth': 64 ## This should be a factor of 8 in some way to stay tensor core friendly\n",
    "    },\n",
    "    'misc': {\n",
    "        'ema': {\n",
    "            'epochs': 180, # Slight bug in that this counts only full epochs and then additionally runs the EMA for any fractional epochs at the end too\n",
    "            'decay_base': .95,\n",
    "            'decay_pow': 3.,\n",
    "            'every_n_steps': 5,\n",
    "        },\n",
    "        'train_epochs': 200,\n",
    "        'device': 'cuda',\n",
    "        'data_location': 'data.pt',\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_model(net, train_dataset, allow_time):\n",
    "    #############################################\n",
    "    #                Dataloader                 #\n",
    "    #############################################\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "    # use the dataloader to get a single batch of all the dataset items at once.\n",
    "    train_dataset_gpu_loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_dataset), drop_last=True,shuffle=True, num_workers=4, persistent_workers=False)\n",
    "    eval_dataset_gpu_loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_dataset_gpu_loader), drop_last=True, shuffle=False, num_workers=1, persistent_workers=False)\n",
    "\n",
    "    train_dataset_gpu = {}\n",
    "    eval_dataset_gpu = {}\n",
    "\n",
    "    train_dataset_gpu['images'], train_dataset_gpu['targets'] = [item.to(device=hyp['misc']['device'], non_blocking=True) for item in next(iter(train_dataset_gpu_loader))]\n",
    "    eval_dataset_gpu['images'],  eval_dataset_gpu['targets']  = [item.to(device=hyp['misc']['device'], non_blocking=True) for item in next(iter(eval_dataset_gpu_loader)) ]\n",
    "\n",
    "    cifar10_std, cifar10_mean = torch.std_mean(train_dataset_gpu['images'], dim=(0, 2, 3)) # dynamically calculate the std and mean from the data. this shortens the code and should help us adapt to new datasets!\n",
    "\n",
    "    def batch_normalize_images(input_images, mean, std):\n",
    "        return (input_images - mean.view(1, -1, 1, 1)) / std.view(1, -1, 1, 1)\n",
    "\n",
    "    # preload with our mean and std\n",
    "    batch_normalize_images = partial(batch_normalize_images, mean=cifar10_mean, std=cifar10_std)\n",
    "\n",
    "    ## Batch normalize datasets, now. Wowie. We did it! We should take a break and make some tea now.\n",
    "    train_dataset_gpu['images'] = batch_normalize_images(train_dataset_gpu['images'])\n",
    "    eval_dataset_gpu['images']  = batch_normalize_images(eval_dataset_gpu['images'])\n",
    "\n",
    "    data = {\n",
    "        'train': train_dataset_gpu,\n",
    "        'eval': eval_dataset_gpu\n",
    "    }\n",
    "\n",
    "    ## Convert dataset to FP16 now for the rest of the process....\n",
    "    data['train']['images'] = data['train']['images'].half().requires_grad_(False)\n",
    "    data['eval']['images']  = data['eval']['images'].half().requires_grad_(False)\n",
    "\n",
    "    # Convert this to one-hot to support the usage of cutmix (or whatever strange label tricks/magic you desire!)\n",
    "    data['train']['targets'] = F.one_hot(data['train']['targets']).half()\n",
    "    data['eval']['targets'] = F.one_hot(data['eval']['targets']).half()\n",
    "\n",
    "    torch.save(data, hyp['misc']['data_location'])\n",
    "\n",
    "\n",
    "    ## This is effectively instantaneous, and takes us practically straight to where the dataloader-loaded dataset would be. :)\n",
    "    ## So as long as you run the above loading process once, and keep the file on the disc it's specified by default in the above\n",
    "    ## hyp dictionary, then we should be good. :)\n",
    "    data = torch.load(hyp['misc']['data_location'])\n",
    "\n",
    "    ## As you'll note above and below, one difference is that we don't count loading the raw data to GPU since it's such a variable operation, and can sort of get in the way\n",
    "    ## of measuring other things. That said, measuring the preprocessing (outside the padding) is still important to us.\n",
    "\n",
    "    # Pad the GPU training dataset\n",
    "    if hyp['net']['pad_amount'] > 0:\n",
    "        ## Uncomfortable shorthand, but basically we pad evenly on all _4_ sides with the pad_amount specified in the original dictionary\n",
    "        data['train']['images'] = F.pad(data['train']['images'], (hyp['net']['pad_amount'],)*4, 'reflect')\n",
    "\n",
    "    # Initializing constants for the whole run.\n",
    "    net_ema = None ## Reset any existing network emas, we want to have _something_ to check for existence so we can initialize the EMA right from where the network is during training\n",
    "                   ## (as opposed to initializing the network_ema from the randomly-initialized starter network, then forcing it to play catch-up all of a sudden in the last several epochs)\n",
    "\n",
    "    total_time_seconds = 0.\n",
    "    current_steps = 0.\n",
    "\n",
    "    # TODO: Doesn't currently account for partial epochs really (since we're not doing \"real\" epochs across the whole batchsize)....\n",
    "    num_steps_per_epoch      = len(data['train']['images']) // batchsize\n",
    "    total_train_steps        = math.ceil(num_steps_per_epoch * hyp['misc']['train_epochs'])\n",
    "    ema_epoch_start          = math.floor(hyp['misc']['train_epochs']) - hyp['misc']['ema']['epochs']\n",
    "\n",
    "    ## I believe this wasn't logged, but the EMA update power is adjusted by being raised to the power of the number of \"every n\" steps\n",
    "    ## to somewhat accomodate for whatever the expected information intake rate is. The tradeoff I believe, though, is that this is to some degree noisier as we\n",
    "    ## are intaking fewer samples of our distribution-over-time, with a higher individual weight each. This can be good or bad depending upon what we want.\n",
    "    projected_ema_decay_val  = hyp['misc']['ema']['decay_base'] ** hyp['misc']['ema']['every_n_steps']\n",
    "\n",
    "    # Adjust pct_start based upon how many epochs we need to finetune the ema at a low lr for\n",
    "    pct_start = hyp['opt']['percent_start'] #* (total_train_steps/(total_train_steps - num_low_lr_steps_for_ema))\n",
    "\n",
    "    ## Stowing the creation of these into a helper function to make things a bit more readable....\n",
    "    non_bias_params, bias_params = fastres.init_split_parameter_dictionaries(net)\n",
    "\n",
    "    # One optimizer for the regular network, and one for the biases. This allows us to use the superconvergence onecycle training policy for our networks....\n",
    "    opt = torch.optim.SGD(**non_bias_params)\n",
    "    opt_bias = torch.optim.SGD(**bias_params)\n",
    "\n",
    "    ## Not the most intuitive, but this basically takes us from ~0 to max_lr at the point pct_start, then down to .1 * max_lr at the end (since 1e16 * 1e-15 = .1 --\n",
    "    ##   This quirk is because the final lr value is calculated from the starting lr value and not from the maximum lr value set during training)\n",
    "    initial_div_factor = 1e16 # basically to make the initial lr ~0 or so :D\n",
    "    final_lr_ratio = .07 # Actually pretty important, apparently!\n",
    "    lr_sched      = torch.optim.lr_scheduler.OneCycleLR(opt,  max_lr=non_bias_params['lr'], pct_start=pct_start, div_factor=initial_div_factor, final_div_factor=1./(initial_div_factor*final_lr_ratio), total_steps=total_train_steps, anneal_strategy='linear', cycle_momentum=False)\n",
    "    lr_sched_bias = torch.optim.lr_scheduler.OneCycleLR(opt_bias, max_lr=bias_params['lr'], pct_start=pct_start, div_factor=initial_div_factor, final_div_factor=1./(initial_div_factor*final_lr_ratio), total_steps=total_train_steps, anneal_strategy='linear', cycle_momentum=False)\n",
    "\n",
    "    ## For accurately timing GPU code\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    torch.cuda.synchronize() ## clean up any pre-net setup operations\n",
    "\n",
    "\n",
    "    if True: ## Sometimes we need a conditional/for loop here, this is placed to save the trouble of needing to indent\n",
    "        for epoch in range(math.ceil(hyp['misc']['train_epochs'])):\n",
    "          #################\n",
    "          # Training Mode #\n",
    "          #################\n",
    "          torch.cuda.synchronize()\n",
    "          starter.record()\n",
    "          net.train()\n",
    "\n",
    "          loss_train = None\n",
    "          accuracy_train = None\n",
    "\n",
    "          cutmix_size = hyp['net']['cutmix_size'] if epoch >= hyp['misc']['train_epochs'] - hyp['net']['cutmix_epochs'] else 0\n",
    "          epoch_fraction = 1 if epoch + 1 < hyp['misc']['train_epochs'] else hyp['misc']['train_epochs'] % 1 # We need to know if we're running a partial epoch or not.\n",
    "\n",
    "          for epoch_step, (inputs, targets) in enumerate(fastres.get_batches(data, key='train', batchsize=batchsize, epoch_fraction=epoch_fraction, cutmix_size=cutmix_size)):\n",
    "              ## Run everything through the network\n",
    "              outputs = net(inputs)\n",
    "\n",
    "              loss_batchsize_scaler = 512/batchsize # to scale to keep things at a relatively similar amount of regularization when we change our batchsize since we're summing over the whole batch\n",
    "              ## If you want to add other losses or hack around with the loss, you can do that here.\n",
    "              loss = fastres.loss_fn(outputs, targets).mul(hyp['opt']['loss_scale_scaler']*loss_batchsize_scaler).sum().div(hyp['opt']['loss_scale_scaler']) ## Note, as noted in the original blog posts, the summing here does a kind of loss scaling\n",
    "                                                     ## (and is thus batchsize dependent as a result). This can be somewhat good or bad, depending...\n",
    "\n",
    "              # we only take the last-saved accs and losses from train\n",
    "              if epoch_step % 50 == 0:\n",
    "                  train_acc = (outputs.detach().argmax(-1) == targets.argmax(-1)).float().mean().item()\n",
    "                  train_loss = loss.detach().cpu().item()/(batchsize*loss_batchsize_scaler)\n",
    "\n",
    "              loss.backward()\n",
    "\n",
    "              ## Step for each optimizer, in turn.\n",
    "              opt.step()\n",
    "              opt_bias.step()\n",
    "\n",
    "              # We only want to step the lr_schedulers while we have training steps to consume. Otherwise we get a not-so-friendly error from PyTorch\n",
    "              lr_sched.step()\n",
    "              lr_sched_bias.step()\n",
    "\n",
    "              ## Using 'set_to_none' I believe is slightly faster (albeit riskier w/ funky gradient update workflows) than under the default 'set to zero' method\n",
    "              opt.zero_grad(set_to_none=True)\n",
    "              opt_bias.zero_grad(set_to_none=True)\n",
    "              current_steps += 1\n",
    "\n",
    "              if epoch >= ema_epoch_start and current_steps % hyp['misc']['ema']['every_n_steps'] == 0:\n",
    "                  ## Initialize the ema from the network at this point in time if it does not already exist.... :D\n",
    "                  if net_ema is None: # don't snapshot the network yet if so!\n",
    "                      net_ema = fastres.NetworkEMA(net)\n",
    "                      continue\n",
    "                  # We warm up our ema's decay/momentum value over training exponentially according to the hyp config dictionary (this lets us move fast, then average strongly at the end).\n",
    "                  net_ema.update(net, decay=projected_ema_decay_val*(current_steps/total_train_steps)**hyp['misc']['ema']['decay_pow'])\n",
    "\n",
    "          ender.record()\n",
    "          torch.cuda.synchronize()\n",
    "          total_time_seconds += 1e-3 * starter.elapsed_time(ender)\n",
    "\n",
    "          ####################\n",
    "          # Evaluation  Mode #\n",
    "          ####################\n",
    "          net.eval()\n",
    "\n",
    "          eval_batchsize = 2500\n",
    "          assert data['eval']['images'].shape[0] % eval_batchsize == 0, \"Error: The eval batchsize must evenly divide the eval dataset (for now, we don't have drop_remainder implemented yet).\"\n",
    "          loss_list_val, acc_list, acc_list_ema = [], [], []\n",
    "\n",
    "          with torch.no_grad():\n",
    "              for inputs, targets in fastres.get_batches(data, key='eval', batchsize=eval_batchsize):\n",
    "                  if epoch >= ema_epoch_start:\n",
    "                      outputs = net_ema(inputs)\n",
    "                      acc_list_ema.append((outputs.argmax(-1) == targets.argmax(-1)).float().mean())\n",
    "                  outputs = net(inputs)\n",
    "                  loss_list_val.append(fastres.loss_fn(outputs, targets).float().mean())\n",
    "                  acc_list.append((outputs.argmax(-1) == targets.argmax(-1)).float().mean())\n",
    "\n",
    "              val_acc = torch.stack(acc_list).mean().item()\n",
    "              ema_val_acc = None\n",
    "              # TODO: We can fuse these two operations (just above and below) all-together like :D :))))\n",
    "              if epoch >= ema_epoch_start:\n",
    "                  ema_val_acc = torch.stack(acc_list_ema).mean().item()\n",
    "\n",
    "              val_loss = torch.stack(loss_list_val).mean().item()\n",
    "          # We basically need to look up local variables by name so we can have the names, so we can pad to the proper column width.\n",
    "          ## Printing stuff in the terminal can get tricky and this used to use an outside library, but some of the required stuff seemed even\n",
    "          ## more heinous than this, unfortunately. So we switched to the \"more simple\" version of this!\n",
    "          format_for_table = lambda x, locals: (f\"{locals[x]}\".rjust(len(x))) \\\n",
    "                                                    if type(locals[x]) == int else \"{:0.4f}\".format(locals[x]).rjust(len(x)) \\\n",
    "                                                if locals[x] is not None \\\n",
    "                                                else \" \"*len(x)\n",
    "\n",
    "          # Print out our training details (sorry for the complexity, the whole logging business here is a bit of a hot mess once the columns need to be aligned and such....)\n",
    "          ## We also check to see if we're in our final epoch so we can print the 'bottom' of the table for each round.\n",
    "          fastres.print_training_details(list(map(partial(format_for_table, locals=locals()), fastres.logging_columns_list)), is_final_entry=(epoch >= math.ceil(hyp['misc']['train_epochs'] - 1)))\n",
    "\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Test defense"
   ],
   "metadata": {
    "id": "THKu7ewXHYGi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6fo4MlW8Cdj"
   },
   "outputs": [],
   "source": [
    "# Get the defended model\n",
    "models = test_defense(clean_model)\n",
    "\n",
    "# Test all attack\n",
    "## Test Pubfig all2all\n",
    "# print(\"----------------- Testing defense result: PubFig all2all -----------------\")\n",
    "# _, test_dataset, asr_dataset, pacc_dataset, _ = PubFig_all2all()\n",
    "# model = models\n",
    "# print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "# print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
    "# print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
    "\n",
    "# ## Test CIFAR-10 SIG\n",
    "print(\"----------------- Testing defense result: CIFAR-10 SIG -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, _ = CIFAR10_SIG()\n",
    "model = models[0]\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
    "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
    "#\n",
    "# ## Test Tiny-Imagenet Narcissus\n",
    "print(\"----------------- Testing defense result: Tiny-Imagenet Narcissus -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, _ = TinyImangeNet_Narcissus()\n",
    "model = models[1]\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
    "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
    "#\n",
    "# ## Test GTSRB WaNet & Smooth\n",
    "print(\"----------------- Testing defense result: GTSRB WaNet & Smooth -----------------\")\n",
    "_, test_dataset, asr_dataset, pacc_dataset, _ = GTSRB_WaNetFrequency()\n",
    "model = models[2]\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
    "print('WaNet ASR %.3f%%' % (100 * get_results(model, asr_dataset[0])))\n",
    "print('WaNet PACC %.3f%%' % (100 * get_results(model, pacc_dataset[0])))\n",
    "print('Smooth ASR %.3f%%' % (100 * get_results(model, asr_dataset[1])))\n",
    "print('Smooth PACC %.3f%%' % (100 * get_results(model, pacc_dataset[1])))\n",
    "#\n",
    "# ## Test STL-10\n",
    "print(\"----------------- Testing defense result: STL-10 -----------------\")\n",
    "_, test_dataset, _, _, _ = STL10_Clean()\n",
    "model = models[3]\n",
    "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. For colab user to release GPU memory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! apt-get install psmisc\n",
    "! /opt/bin/nvidia-smi\n",
    "! sudo fuser -v/dev/nvidia *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! kill -9[PID]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b8be34f2a64f133f414bd034f75b72cc1c8d29070f6944ffe8bd65ff6cd5b9f"
   }
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "WkI4fII__74u",
    "TV_oFkq28Cdg",
    "GFxsTR3E8Cdj",
    "THKu7ewXHYGi"
   ]
  },
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
